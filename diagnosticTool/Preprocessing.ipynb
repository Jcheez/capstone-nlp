{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "id": "cZ54V0fZzgkC",
        "outputId": "e528149e-f223-483b-8e83-b69d9ab99838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emot\n",
            "  Downloading emot-3.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 20 kB/s \n",
            "\u001b[?25hInstalling collected packages: emot\n",
            "Successfully installed emot-3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyDictionary\n",
            "  Downloading PyDictionary-2.0.1-py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from PyDictionary) (0.0.1)\n",
            "Collecting goslate\n",
            "  Downloading goslate-1.5.4.tar.gz (14 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from PyDictionary) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from PyDictionary) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->PyDictionary) (4.6.3)\n",
            "Collecting futures\n",
            "  Downloading futures-3.0.5.tar.gz (25 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/55/db/97c1ca37edab586a1ae03d6892b6633d8eaa23b23ac40c7e5bbc55423c78/futures-3.0.5.tar.gz#sha256=0542525145d5afc984c88f914a0c85c77527f65946617edb5274f72406f981df (from https://pypi.org/simple/futures/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading futures-3.0.4.tar.gz (25 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/8d/73/b5fff618482bc06c9711e7cdc0d5d7eb1904d35898f48f2d7f9696b08bef/futures-3.0.4.tar.gz#sha256=19485d83f7bd2151c0aeaf88fbba3ee50dadfb222ffc3b66a344ef4952b782a3 (from https://pypi.org/simple/futures/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading futures-3.0.3.tar.gz (24 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/4c/dc/f9473006d4c9c52d4a4e977173fbcbfb1a8ef3a57e32e885edf994fd4a45/futures-3.0.3.tar.gz#sha256=2fe2342bb4fe8b8e217f0d21b5921cbe5408bf966d9f92025e707e881b198bed (from https://pypi.org/simple/futures/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading futures-3.0.2.tar.gz (24 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/f8/e7/fc0fcbeb9193ba2d4de00b065e7fd5aecd0679e93ce95a07322b2b1434f4/futures-3.0.2.tar.gz#sha256=dc3fc91508e49e0fd2f8625f0132d16e49c80f882e7e1d565c56b0d5dfbae257 (from https://pypi.org/simple/futures/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading futures-3.0.1.tar.gz (24 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/b2/2c/6b6a57379e47031c6f52e625e0e2b8f6702a8d1f61b6e0daee391e82c187/futures-3.0.1.tar.gz#sha256=f78f2ef458639d72a625cf9c7643cf5442bb222ac11c12bcc445c6ad1cd862e2 (from https://pypi.org/simple/futures/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading futures-3.0.0.tar.gz (24 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/ea/c9/35287369718fc05059e7a9d0d73c53745fe981010b4185b3858e7d46eff1/futures-3.0.0.tar.gz#sha256=d9cd7bb09aa01f0e4940af64c31fbd7045098b7b4354420d7838ea39e8b86ee3 (from https://pypi.org/simple/futures/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading futures-2.2.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->PyDictionary) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->PyDictionary) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->PyDictionary) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->PyDictionary) (3.0.4)\n",
            "Building wheels for collected packages: goslate\n",
            "  Building wheel for goslate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for goslate: filename=goslate-1.5.4-py3-none-any.whl size=11597 sha256=161583c0146d0a81aa71fc86691859194fdf275e72e98ae35825ff293fdf5d6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/08/d5/88fc81ecccbff86db9b3dac7ca657c2cc64b5d10db421bd2a2\n",
            "Successfully built goslate\n",
            "Installing collected packages: futures, goslate, PyDictionary\n",
            "Successfully installed PyDictionary-2.0.1 futures-2.2.0 goslate-1.5.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "concurrent"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installations complete\n"
          ]
        }
      ],
      "source": [
        "# Installations\n",
        "!pip install emot\n",
        "!pip install nltk\n",
        "!pip install PyDictionary\n",
        "print(\"Installations complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEUj2fCZdYIv",
        "outputId": "4c43d336-f11b-4a92-9dc3-71a5220c20dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries have been successfully imported\n"
          ]
        }
      ],
      "source": [
        "# Libraries to import\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import emot\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import words\n",
        "from nltk.tokenize import word_tokenize\n",
        "from PyDictionary import PyDictionary\n",
        "from nltk.stem import PorterStemmer\n",
        "print(\"Libraries have been successfully imported\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yPfGnyJeakC",
        "outputId": "fc899581-b072-4df1-b568-c4119cb33a5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Ensure you make a shortcut of BT4013 CAPSTONE on own drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "training_set_path = \"/content/drive/MyDrive/BT4103 CAPSTONE/Data/assets/sensitised_IG_RnR_training_dataset.xlsx\"\n",
        "emoji_dict_path = \"/content/drive/MyDrive/BT4103 CAPSTONE/Data/assets/emoji.xlsx\"\n",
        "emoticon_dict_path = \"/content/drive/MyDrive/BT4103 CAPSTONE/Data/assets/emoticons.xlsx\"\n",
        "nonenglish_dict_path = \"/content/drive/MyDrive/BT4103 CAPSTONE/Data/assets/nonenglish.xlsx\"\n",
        "\n",
        "test_set_path = \"/content/drive/MyDrive/BT4103 CAPSTONE/Data/assets/sensitised_IG_RnR_datasets_SingBert_labelled.xlsx\"\n",
        "test_emoji_dict_path = \"/content/drive/MyDrive/BT4103 CAPSTONE/Data/assets/test_emoji.xlsx\"\n",
        "test_emoticon_dict_path = \"/content/drive/MyDrive/BT4103 CAPSTONE/Data/assets/test_emoticons.xlsx\"\n",
        "test_nonenglish_dict_path = \"/content/drive/MyDrive/BT4103 CAPSTONE/Data/assets/test_nonenglish.xlsx\""
      ],
      "metadata": {
        "id": "nMt_L_pdl54K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "H20AUc1ggEpX",
        "outputId": "aa62e83c-5006-48dc-ada2-24b907fc1a9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     page                                               text   label\n",
              "0.0   0.0  @bgAABHtNhL is synonymous with Girlfriends, a ...  others\n",
              "1.0   0.0  A Malay Muslim desktop engineer by trade, @bgA...  others\n",
              "2.0   0.0  A Malay Muslim desktop engineer by trade, @bgA...  others\n",
              "3.0   0.0  We're celebrating this July! 🎉 \\n \\nJoin our C...  others\n",
              "4.0   0.0  Be the change you want to see, they say. How d...  others"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9108738a-4250-43c6-b9db-dec417cd1bca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>@bgAABHtNhL is synonymous with Girlfriends, a ...</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>A Malay Muslim desktop engineer by trade, @bgA...</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>A Malay Muslim desktop engineer by trade, @bgA...</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>We're celebrating this July! 🎉 \\n \\nJoin our C...</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Be the change you want to see, they say. How d...</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9108738a-4250-43c6-b9db-dec417cd1bca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9108738a-4250-43c6-b9db-dec417cd1bca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9108738a-4250-43c6-b9db-dec417cd1bca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Import Training dataset\n",
        "data = pd.read_excel(training_set_path, index_col=0)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emoji_engine = emot.core.emot()\n",
        "emoji_engine.bulk_emoji([\"@bgAABHAPTM.tm_ 😂😂\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CgoCDQ6YEFH",
        "outputId": "b26f27d0-d492-4ef1-d7ef-58e555a1b568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'value': ['😂', '😂'],\n",
              "  'location': [[16, 17], [17, 18]],\n",
              "  'mean': [':face_with_tears_of_joy:', ':face_with_tears_of_joy:'],\n",
              "  'flag': True}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ALL FUNCTIONS WILL RESIDE IN THIS CODE TAB\n",
        "def icons_to_words(isEmoji:bool, dataset_path:str, text_col:str) -> dict:\n",
        "  '''\n",
        "  This function finds all emojis/emoticons in a chunk of text and assigns a default meaning to it\n",
        "  Returns: A dictionary of an emoji/emoticon with its assigned meaning\n",
        "  '''\n",
        "  data = pd.read_excel(dataset_path, index_col=0)\n",
        "  emoji_engine = emot.core.emot()\n",
        "  storage = {}\n",
        "  text_list = data[text_col].tolist()\n",
        "  breakdown = list(map(lambda x: (x['value'], x['mean']), emoji_engine.bulk_emoji(text_list))) if isEmoji else list(map(lambda x: (x['value'], x['mean']), emoji_engine.bulk_emoticons(text_list)))\n",
        "\n",
        "  for emoji_list, mean_list in breakdown:\n",
        "    for i in range(len(emoji_list)):\n",
        "      if emoji_list[i] not in storage:\n",
        "        storage[emoji_list[i]] = mean_list[i].replace(':', \"\").replace('_', \" \")\n",
        "  return storage\n",
        "\n",
        "\n",
        "def update_external_corpus(path:str, column_names:list, corpus:dict) -> None:\n",
        "  '''\n",
        "  Updates the external xlsx corpus files with newly added words\n",
        "  '''\n",
        "  corpus_present = os.path.isfile(path)\n",
        "  if not corpus_present:\n",
        "    temp_df = pd.DataFrame(columns=column_names)\n",
        "    for feature, desc in corpus.items():\n",
        "      temp_df = temp_df.append({column_names[0]:feature, column_names[1]:desc}, ignore_index=True)\n",
        "  else:\n",
        "    temp_df = pd.read_excel(path)\n",
        "    features = set()\n",
        "    for feature in temp_df[column_names[0]]:\n",
        "      features.add(feature)\n",
        "    for feature, desc in corpus.items():\n",
        "      if feature not in features:\n",
        "        temp_df = temp_df.append({column_names[0]:feature, column_names[1]:desc}, ignore_index=True)\n",
        "  temp_df.to_excel(path, index=False)\n",
        "\n",
        "\n",
        "def convert_emojis_to_word(text:str, storage:dict) -> str:\n",
        "  '''\n",
        "  Function used to preprocess emojis to words\n",
        "  '''\n",
        "  for emot in storage:\n",
        "    if text is not np.nan:\n",
        "      text = re.sub(r'('+emot+')', \" \".join(storage[emot].split()), text)\n",
        "  return text\n",
        "\n",
        "\n",
        "def convert_emoticons_to_words(text:str, storage:dict) -> str:\n",
        "  '''\n",
        "  Function used to preprocess emoticons to words\n",
        "  '''\n",
        "  for emot in storage:\n",
        "    if text is not np.nan:\n",
        "      text = text.replace(emot, storage[emot])\n",
        "  return text\n",
        "\n",
        "\n",
        "def find_sus_english_words(storage:dict, text:str, ps=PorterStemmer()):\n",
        "  '''\n",
        "  Use NLTK to shortlist possible words that are not in English\n",
        "  '''\n",
        "  text_list = word_tokenize(text)\n",
        "  for token in text_list:\n",
        "    if ps.stem(token) not in setofwords and token not in storage and token.isalpha():\n",
        "      storage[token] = token\n",
        "\n",
        "\n",
        "\n",
        "def find_non_english_words(storage:dict, book=PyDictionary()):\n",
        "  '''\n",
        "  Using an online scraper to check and confirm if word is not English, VERY EXPENSIVE\n",
        "  '''\n",
        "  temp_store = {}\n",
        "  for token,_ in storage.items():\n",
        "    if not bool(book.meaning(token)):\n",
        "      temp_store[token] = token\n",
        "  return temp_store\n",
        "\n",
        "\n",
        "def preprocessing_engine(dataset_path:str, text_col:str):\n",
        "  '''\n",
        "  PREPROCESSING STEPS\n",
        "  1. Replace emojis with words\n",
        "  2. Remove all <@usernames>\n",
        "  3. Remove all <#Hashtags>\n",
        "  4. Remove all URLS (Links beginning with http or https)\n",
        "  5. Remove all emails\n",
        "  6. Replace emoticons with words.\n",
        "  7. Change all letters to lower case\n",
        "  8. Remove all new lines, new tabs or carriage returns\n",
        "  9. Ensure there is only 1 whitespace between words\n",
        "  '''\n",
        "  data = pd.read_excel(dataset_path, index_col=0) # Temporary fix to training set issues\n",
        "  data[text_col] = data[text_col].apply(lambda x: convert_emojis_to_word(x, emoji_dict))\n",
        "  data[text_col] = data[text_col].str.replace(\"\\B\\@\\S+ |\\B\\@\\S+\", \"\", regex=True)\n",
        "  data[text_col] = data[text_col].str.replace(\"\\B\\#\\S+ |\\B\\#\\S+\", \"\", regex=True)\n",
        "  data[text_col] = data[text_col].str.replace('(?:https?|ftp):\\/\\/[\\w/\\-?=%.]+\\.[\\w/\\-&?=%.]+', \"\", regex=True)\n",
        "  data[text_col] = data[text_col].str.replace('[a-zA-Z0-9-_.]+@[a-zA-Z0-9-_.]+', \"\", regex=True)\n",
        "  data[text_col] = data[text_col].apply(lambda x: convert_emoticons_to_words(x, emoticons_dict))\n",
        "  data[text_col] = data[text_col].str.lower()\n",
        "  data[text_col] = data[text_col].str.replace('\\r+|\\n+|\\t+',' ', regex=True)\n",
        "  data[text_col] = data[text_col].apply(lambda x: \" \".join(x.split()) if x is not np.nan else x)\n",
        "  return data"
      ],
      "metadata": {
        "id": "z2UDqvHi_zxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###### DIAGNOSTIC: PLEASE SET THE CORRECT PATHS BEFORE RUNNING THE FOLLOWING FUNCTIONS ######\n",
        "target_dataset_path = test_set_path\n",
        "target_emoji_path = emoji_dict_path\n",
        "target_emoticons_path = emoticon_dict_path\n",
        "target_shortform_path = test_nonenglish_dict_path"
      ],
      "metadata": {
        "id": "tTxtTmYdckNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHnw_Rdv2cZq",
        "outputId": "ef571c70-842f-4336-e1fc-02b3c369cd85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'👋': 'waving hand', '🎉': 'party popper', '👈': 'backhand index pointing left', '✨': 'sparkles', '🎨': 'artist palette', '🙏': 'folded hands', '🙌': 'raising hands', '🌙': 'crescent moon', '✅': 'check mark button', '✏': 'pencil', '📸': 'camera with flash', '✊🏽': 'raised fist medium skin tone', '❤': 'red heart', '🌸': 'cherry blossom', '🌈': 'rainbow', '🎙': 'studio microphone', '😔': 'pensive face', '🙄': 'face with rolling eyes', '😢': 'crying face', '💬': 'speech balloon', '📖': 'open book', '🤦🏻\\u200d♀️': 'woman facepalming light skin tone'}\n"
          ]
        }
      ],
      "source": [
        "# Core logic of emoji / emoticions -> words\n",
        "emoji_dict = icons_to_words(True, target_dataset_path, 'text')\n",
        "update_external_corpus(target_emoji_path, [\"Emoji\", \"Meaning\"], emoji_dict)\n",
        "print(emoji_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emoticons_dict = icons_to_words(False, target_dataset_path, 'text')\n",
        "update_external_corpus(target_emoticons_path, [\"Emoticon\", \"Meaning\"], emoticons_dict)\n",
        "print(emoticons_dict)"
      ],
      "metadata": {
        "id": "D5qSyNb88wYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e9fca0-c5d5-4313-9da6-e4d55f8b2a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{':/': 'Skeptical, annoyed, undecided, uneasy or hesitant', 'd:': 'Tongue sticking out, cheeky, playful or blowing a raspberry', ';)': 'Wink or smirk', ':)': 'Happy face or smiley', '=D': 'Laughing, big grin or laugh with glasses', ':3': 'Happy face smiley', ';D': 'Wink or smirk', 'QQ': 'Sad or Crying', 'DX': 'Great dismay', 'oO': 'Surprised', '=3': 'Laughing, big grin or laugh with glasses', '=p': 'Tongue sticking out, cheeky, playful or blowing a raspberry', 'XP': 'Tongue sticking out, cheeky, playful or blowing a raspberry', ':>': 'Happy face smiley', '0:3': 'Angel, saint or innocent', 'XD': 'Laughing, big grin or laugh with glasses', ':(': 'Frown, sad, andry or pouting', ':-(': 'Frown, sad, andry or pouting', ':o': 'Surprise', '=/': 'Skeptical, annoyed, undecided, uneasy or hesitant', '8D': 'Laughing, big grin or laugh with glasses', '>:)': 'Evil or devilish', '=L': 'Skeptical, annoyed, undecided, uneasy or hesitant', ':<': 'Frown, sad, andry or pouting', \":')\": 'Tears of happiness', ':*': 'Kiss', ':D': 'Laughing, big grin or laugh with glasses', ':c': 'Frown, sad, andry or pouting', ':))': 'Very Happy face or smiley', ':S': 'Skeptical, annoyed, undecided, uneasy or hesitant', ':@': 'Frown, sad, andry or pouting', 'D8': 'Great dismay', ':)))': 'Very very Happy face or smiley', '%)': 'Drunk or confused', ';;': 'Sad or Crying', ':|': 'Straight face', '=)': 'Happy face smiley', ':O': 'Surprise', ':-)': 'Happy face smiley', '>:(': 'Frown, sad, andry or pouting', 'D:': 'Sadness', ':P': 'Tongue sticking out, cheeky, playful or blowing a raspberry', ';-;': 'Sad or Crying'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_dataset = preprocessing_engine(target_dataset_path, 'text')\n",
        "processed_dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "t3gsp9NODbmT",
        "outputId": "1b81d576-b2eb-4431-d8ce-86068a1113b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     group                                                 id  \\\n",
              "0.0    0.0  b'gAAAAABjHsN3lwZhNGi-AiGMiKAlaqsf5Okowm6bY8XY...   \n",
              "1.0    1.0  b'gAAAAABjHsN3jpTi8BHHJ22-VFogHsPfs0xtvStni-tm...   \n",
              "2.0    1.0  b'gAAAAABjHsN39aHFT9kD5vWMDdDeyoSxhOBV207WC_Pr...   \n",
              "3.0    2.0  b'gAAAAABjHsN3Vlhtr6w4HR1DrSzzLaUZREcBhwJHYt3j...   \n",
              "4.0    2.0  b'gAAAAABjHsN3tRg6EgulC0KBsGRn02OFptSKHsQjGqlc...   \n",
              "\n",
              "                                                  text                time  \\\n",
              "0.0  in part 2 of her article, n.h rahman analyses ... 2021-12-18 14:58:28   \n",
              "1.0  hidayah amin is a force to be reckoned with. h... 2021-12-15 18:00:33   \n",
              "2.0  this year, we get up close and personal with t... 2021-12-14 18:01:04   \n",
              "3.0                           edwin tong strikes again 2021-12-14 09:59:12   \n",
              "4.0  congratulations loh kean yew! he just best the... 2021-12-14 00:48:54   \n",
              "\n",
              "      likes  comments  type  post_id comment_id  text_pred  text_pred_prob  \\\n",
              "0.0    35.0       0.0  Post      NaN        NaN        2.0        0.999916   \n",
              "1.0   100.0       0.0  Post      NaN        NaN        3.0        0.999840   \n",
              "2.0    72.0       2.0  Post      NaN        NaN        1.0        0.991582   \n",
              "3.0  2516.0       9.0  Post      NaN        NaN        3.0        0.999707   \n",
              "4.0  3519.0      31.0  Post      NaN        NaN        1.0        0.983010   \n",
              "\n",
              "          text_label  \n",
              "0.0  social activism  \n",
              "1.0       solidarity  \n",
              "2.0           others  \n",
              "3.0       solidarity  \n",
              "4.0           others  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65c455d5-9240-447d-9516-71094f3b09d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>group</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>time</th>\n",
              "      <th>likes</th>\n",
              "      <th>comments</th>\n",
              "      <th>type</th>\n",
              "      <th>post_id</th>\n",
              "      <th>comment_id</th>\n",
              "      <th>text_pred</th>\n",
              "      <th>text_pred_prob</th>\n",
              "      <th>text_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>b'gAAAAABjHsN3lwZhNGi-AiGMiKAlaqsf5Okowm6bY8XY...</td>\n",
              "      <td>in part 2 of her article, n.h rahman analyses ...</td>\n",
              "      <td>2021-12-18 14:58:28</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Post</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.999916</td>\n",
              "      <td>social activism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>b'gAAAAABjHsN3jpTi8BHHJ22-VFogHsPfs0xtvStni-tm...</td>\n",
              "      <td>hidayah amin is a force to be reckoned with. h...</td>\n",
              "      <td>2021-12-15 18:00:33</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Post</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.999840</td>\n",
              "      <td>solidarity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>b'gAAAAABjHsN39aHFT9kD5vWMDdDeyoSxhOBV207WC_Pr...</td>\n",
              "      <td>this year, we get up close and personal with t...</td>\n",
              "      <td>2021-12-14 18:01:04</td>\n",
              "      <td>72.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Post</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.991582</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>b'gAAAAABjHsN3Vlhtr6w4HR1DrSzzLaUZREcBhwJHYt3j...</td>\n",
              "      <td>edwin tong strikes again</td>\n",
              "      <td>2021-12-14 09:59:12</td>\n",
              "      <td>2516.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Post</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.999707</td>\n",
              "      <td>solidarity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>b'gAAAAABjHsN3tRg6EgulC0KBsGRn02OFptSKHsQjGqlc...</td>\n",
              "      <td>congratulations loh kean yew! he just best the...</td>\n",
              "      <td>2021-12-14 00:48:54</td>\n",
              "      <td>3519.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>Post</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.983010</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65c455d5-9240-447d-9516-71094f3b09d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65c455d5-9240-447d-9516-71094f3b09d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65c455d5-9240-447d-9516-71094f3b09d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If shortforms corpus already exists, then this step is not necessary to run as it is very expensive\n",
        "\n",
        "setofwords = set(words.words())\n",
        "non_english = {}\n",
        "\n",
        "processed_dataset['text'].apply(lambda x: find_sus_english_words(non_english, x) if x is not np.nan else x)\n",
        "\n",
        "update_external_corpus(target_shortform_path, [\"Word\", \"Meaning\"], find_non_english_words(non_english))"
      ],
      "metadata": {
        "id": "4BE88LqEXqRZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}